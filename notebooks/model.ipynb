{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7b67f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "620d8f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_df = pd.read_csv(r\"E:\\environments\\wallmart_hackathon\\dataset\\m5-forecasting-accuracy\\calendar.csv\")\n",
    "sales_validation_df = pd.read_csv(r\"E:\\environments\\wallmart_hackathon\\dataset\\m5-forecasting-accuracy\\sales_train_validation.csv\")\n",
    "sell_prices_df = pd.read_csv(r\"E:\\environments\\wallmart_hackathon\\dataset\\m5-forecasting-accuracy\\sell_prices.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ea8dd",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c17da43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3811250, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1789</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id       d  sales  \n",
       "0       CA  d_1789      0  \n",
       "1       CA  d_1789      0  \n",
       "2       CA  d_1789      1  \n",
       "3       CA  d_1789      1  \n",
       "4       CA  d_1789      2  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## melting last 120 days (form d_1789 to d_1913)\n",
    "## lag = 28, rolling mean = 28\n",
    "\n",
    "start_col = 1789\n",
    "end_col = 1913\n",
    "\n",
    "col = [f'd_{x}' for x in range(start_col, end_col + 1)]\n",
    "\n",
    "columns = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'] + col\n",
    "\n",
    "sub_validation_df = sales_validation_df[columns]\n",
    "\n",
    "sales_long = sub_validation_df.melt(\n",
    "    id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    "    var_name='d',\n",
    "    value_name='sales'\n",
    ")\n",
    "\n",
    "print(sales_long.shape)\n",
    "sales_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "35e73762",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge with calendar\n",
    "\n",
    "sales_long = sales_long.merge(calendar_df, how = 'left', on = 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a84bd811",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert date to datetime\n",
    "sales_long['date'] = pd.to_datetime(sales_long['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "99ab0aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge with sales_prices\n",
    "sales_long = sales_long.merge(sell_prices_df, how = 'left', on = ['store_id', 'item_id', 'wm_yr_wk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe16c064",
   "metadata": {},
   "source": [
    "sales_long is the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9262c66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1789</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>11547</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1789</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>11547</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1789</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>11547</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1789</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>11547</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1789</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>11547</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id       d  sales       date  wm_yr_wk  ... month  year  event_name_1  \\\n",
       "0       CA  d_1789      0 2015-12-22     11547  ...    12  2015           NaN   \n",
       "1       CA  d_1789      0 2015-12-22     11547  ...    12  2015           NaN   \n",
       "2       CA  d_1789      1 2015-12-22     11547  ...    12  2015           NaN   \n",
       "3       CA  d_1789      1 2015-12-22     11547  ...    12  2015           NaN   \n",
       "4       CA  d_1789      2 2015-12-22     11547  ...    12  2015           NaN   \n",
       "\n",
       "   event_type_1 event_name_2 event_type_2 snap_CA snap_TX  snap_WI  sell_price  \n",
       "0           NaN          NaN          NaN       0       0        0        8.26  \n",
       "1           NaN          NaN          NaN       0       0        0        3.97  \n",
       "2           NaN          NaN          NaN       0       0        0        2.97  \n",
       "3           NaN          NaN          NaN       0       0        0        4.64  \n",
       "4           NaN          NaN          NaN       0       0        0        2.88  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c336e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_long = sales_long.sort_values(['id', 'date'])\n",
    "\n",
    "## create lag of 28\n",
    "sales_long['lag_28'] = (\n",
    "    sales_long\n",
    "    .groupby('id')['sales']\n",
    "    .shift(28)\n",
    ")\n",
    "\n",
    "## create lag of 7\n",
    "sales_long['lag_7'] = (\n",
    "    sales_long\n",
    "    .groupby('id')['sales']\n",
    "    .shift(7)\n",
    ")\n",
    "\n",
    "## rolling mean of 28\n",
    "sales_long['rolling_mean_28'] = (\n",
    "    sales_long\n",
    "    .groupby('id')['sales']\n",
    "    .transform(\n",
    "        lambda x: x.shift(1).rolling(window=28).mean()\n",
    "    )\n",
    ")\n",
    "\n",
    "# ## percent price change feature\n",
    "sales_long[\"price_pct_change\"] = (\n",
    "    sales_long.groupby(\"id\")[\"sell_price\"]\n",
    "    .pct_change(fill_method = None).fillna(0)\n",
    ")\n",
    "\n",
    "# ## zero streaks\n",
    "sales_long[\"zero_streak\"] = (\n",
    "    sales_long.groupby(\"id\")[\"sales\"]\n",
    "    .transform(lambda x: x.eq(0).astype(int).groupby(x.ne(0).cumsum()).cumsum())\n",
    ")\n",
    "\n",
    "\n",
    "## calendar features\n",
    "sales_long['month'] = sales_long['date'].dt.month\n",
    "sales_long['year'] = sales_long['date'].dt.year\n",
    "\n",
    "sales_long['day_of_month'] = sales_long['date'].dt.day\n",
    "sales_long['week_of_month'] = ((sales_long['day_of_month'] - 1) // 7) + 1\n",
    "\n",
    "sales_long.head()\n",
    "\n",
    "\n",
    "## target columns\n",
    "## Reverse the time series so rolling looks \"forward\"\n",
    "sales_long['sales_28_sum'] = (\n",
    "    sales_long\n",
    "    .iloc[::-1]                                 \n",
    "    .groupby('id')['sales']\n",
    "    .rolling(window=28, min_periods=28)\n",
    "    .sum()\n",
    "    .reset_index(level=0, drop=True)\n",
    "    .iloc[::-1]                               \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    sales_long[\"state_id\"] == \"CA\",\n",
    "    sales_long[\"state_id\"] == \"TX\",\n",
    "    sales_long[\"state_id\"] == \"WI\"\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    sales_long[\"snap_CA\"],\n",
    "    sales_long[\"snap_TX\"],\n",
    "    sales_long[\"snap_WI\"]\n",
    "]\n",
    "\n",
    "sales_long[\"snap_active\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "sales_long.drop(['snap_CA', 'snap_TX', 'snap_WI'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7fa76ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "item_id                  0\n",
       "dept_id                  0\n",
       "cat_id                   0\n",
       "store_id                 0\n",
       "state_id                 0\n",
       "d                        0\n",
       "sales                    0\n",
       "date                     0\n",
       "wm_yr_wk                 0\n",
       "weekday                  0\n",
       "wday                     0\n",
       "month                    0\n",
       "year                     0\n",
       "event_name_1       3445370\n",
       "event_type_1       3445370\n",
       "event_name_2       3811250\n",
       "event_type_2       3811250\n",
       "snap_CA                  0\n",
       "snap_TX                  0\n",
       "snap_WI                  0\n",
       "sell_price             705\n",
       "lag_28              853720\n",
       "lag_7               213430\n",
       "rolling_mean_28     853720\n",
       "day_of_month             0\n",
       "week_of_month            0\n",
       "sales_28_sum        823230\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_long.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b8772fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2134300, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>lag_28</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>rolling_mean_28</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>week_of_month</th>\n",
       "      <th>sales_28_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>855332</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1817</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>11551</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885822</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1818</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>11551</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916312</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1819</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>11551</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946802</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1820</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>11551</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977292</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1821</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>11552</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id      item_id  dept_id cat_id store_id  \\\n",
       "855332  FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "885822  FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "916312  FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "946802  FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "977292  FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "\n",
       "       state_id       d  sales       date  wm_yr_wk  ... snap_CA  snap_TX  \\\n",
       "855332       CA  d_1817      0 2016-01-19     11551  ...       0        0   \n",
       "885822       CA  d_1818      0 2016-01-20     11551  ...       0        0   \n",
       "916312       CA  d_1819      1 2016-01-21     11551  ...       0        0   \n",
       "946802       CA  d_1820      0 2016-01-22     11551  ...       0        0   \n",
       "977292       CA  d_1821      0 2016-01-23     11552  ...       0        0   \n",
       "\n",
       "        snap_WI  sell_price lag_28 lag_7 rolling_mean_28 day_of_month  \\\n",
       "855332        0        2.24    1.0   0.0        0.464286           19   \n",
       "885822        0        2.24    2.0   2.0        0.428571           20   \n",
       "916312        0        2.24    0.0   0.0        0.357143           21   \n",
       "946802        0        2.24    0.0   0.0        0.392857           22   \n",
       "977292        0        2.24    1.0   0.0        0.392857           23   \n",
       "\n",
       "        week_of_month  sales_28_sum  \n",
       "855332              3          23.0  \n",
       "885822              3          23.0  \n",
       "916312              3          24.0  \n",
       "946802              4          23.0  \n",
       "977292              4          24.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_long = sales_long.dropna(subset=['lag_28', 'lag_7', 'rolling_mean_28', 'sales_28_sum'])\n",
    "print(sales_long.shape)\n",
    "sales_long.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7df950df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'd',\n",
       "       'sales', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
       "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
       "       'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_28', 'lag_7',\n",
       "       'rolling_mean_28', 'day_of_month', 'week_of_month', 'sales_28_sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_long.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aa6a37df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>week_of_month</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>lag_28</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>rolling_mean_28</th>\n",
       "      <th>sales_28_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>855332</th>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885822</th>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916312</th>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946802</th>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977292</th>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864622</th>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Purim End</td>\n",
       "      <td>Religious</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895112</th>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925602</th>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956092</th>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Easter</td>\n",
       "      <td>Cultural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986582</th>\n",
       "      <td>HOUSEHOLD_2_516</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2134300 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 item_id      dept_id store_id state_id    weekday  month  \\\n",
       "855332       FOODS_1_001      FOODS_1     CA_1       CA    Tuesday      1   \n",
       "885822       FOODS_1_001      FOODS_1     CA_1       CA  Wednesday      1   \n",
       "916312       FOODS_1_001      FOODS_1     CA_1       CA   Thursday      1   \n",
       "946802       FOODS_1_001      FOODS_1     CA_1       CA     Friday      1   \n",
       "977292       FOODS_1_001      FOODS_1     CA_1       CA   Saturday      1   \n",
       "...                  ...          ...      ...      ...        ...    ...   \n",
       "2864622  HOUSEHOLD_2_516  HOUSEHOLD_2     WI_3       WI   Thursday      3   \n",
       "2895112  HOUSEHOLD_2_516  HOUSEHOLD_2     WI_3       WI     Friday      3   \n",
       "2925602  HOUSEHOLD_2_516  HOUSEHOLD_2     WI_3       WI   Saturday      3   \n",
       "2956092  HOUSEHOLD_2_516  HOUSEHOLD_2     WI_3       WI     Sunday      3   \n",
       "2986582  HOUSEHOLD_2_516  HOUSEHOLD_2     WI_3       WI     Monday      3   \n",
       "\n",
       "         week_of_month event_name_1 event_type_1 event_name_2 event_type_2  \\\n",
       "855332               3          NaN          NaN          NaN          NaN   \n",
       "885822               3          NaN          NaN          NaN          NaN   \n",
       "916312               3          NaN          NaN          NaN          NaN   \n",
       "946802               4          NaN          NaN          NaN          NaN   \n",
       "977292               4          NaN          NaN          NaN          NaN   \n",
       "...                ...          ...          ...          ...          ...   \n",
       "2864622              4    Purim End    Religious          NaN          NaN   \n",
       "2895112              4          NaN          NaN          NaN          NaN   \n",
       "2925602              4          NaN          NaN          NaN          NaN   \n",
       "2956092              4       Easter     Cultural          NaN          NaN   \n",
       "2986582              4          NaN          NaN          NaN          NaN   \n",
       "\n",
       "         snap_CA  snap_TX  snap_WI  sell_price  lag_28  lag_7  \\\n",
       "855332         0        0        0        2.24     1.0    0.0   \n",
       "885822         0        0        0        2.24     2.0    2.0   \n",
       "916312         0        0        0        2.24     0.0    0.0   \n",
       "946802         0        0        0        2.24     0.0    0.0   \n",
       "977292         0        0        0        2.24     1.0    0.0   \n",
       "...          ...      ...      ...         ...     ...    ...   \n",
       "2864622        0        0        0        5.94     0.0    0.0   \n",
       "2895112        0        0        0        5.94     0.0    0.0   \n",
       "2925602        0        0        0        5.94     0.0    0.0   \n",
       "2956092        0        0        0        5.94     1.0    0.0   \n",
       "2986582        0        0        0        5.94     0.0    0.0   \n",
       "\n",
       "         rolling_mean_28  sales_28_sum  \n",
       "855332          0.464286          23.0  \n",
       "885822          0.428571          23.0  \n",
       "916312          0.357143          24.0  \n",
       "946802          0.392857          23.0  \n",
       "977292          0.392857          24.0  \n",
       "...                  ...           ...  \n",
       "2864622         0.107143           0.0  \n",
       "2895112         0.107143           0.0  \n",
       "2925602         0.107143           0.0  \n",
       "2956092         0.107143           0.0  \n",
       "2986582         0.071429           0.0  \n",
       "\n",
       "[2134300 rows x 19 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_columns = ['item_id', 'dept_id', 'store_id', 'state_id', 'weekday', 'month', 'week_of_month', 'event_name_1', 'event_type_1', 'event_name_2', \n",
    "                 'event_type_2','snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_28', 'lag_7', 'rolling_mean_28', 'sales_28_sum']\n",
    "\n",
    "final_df = sales_long[final_columns]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "71893e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'dept_id', 'store_id', 'state_id', 'weekday', 'month',\n",
       "       'week_of_month', 'event_name_1', 'event_type_1', 'event_name_2',\n",
       "       'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_28',\n",
       "       'lag_7', 'rolling_mean_28', 'sales_28_sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa09b5",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3872db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "df34273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data transformation \n",
    "class PreProcessor:\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.X = dataframe.drop('sales_28_sum', inplace = False, axis = 1)\n",
    "        self.y = dataframe['sales_28_sum']\n",
    "        self.encoders = {}\n",
    "        self.scalers = None\n",
    "\n",
    "    def get_train_test_split(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size = 0.2, random_state = 42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def get_nan_value_imputing(self, X_train, X_test):\n",
    "        event_cols = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "        for col in event_cols:\n",
    "            X_train[col] = X_train[col].fillna('No_event')\n",
    "            X_test[col] = X_test[col].fillna('No_event')\n",
    "\n",
    "        for df in [X_train, X_test]:\n",
    "            df['sell_price'] = (\n",
    "            df.groupby(['store_id', 'item_id'])['sell_price']\n",
    "            .transform(lambda x: x.ffill().bfill())\n",
    "            )\n",
    "        return X_train, X_test\n",
    "    \n",
    "    def get_label_encoding(self, X_train, X_test):\n",
    "        label_encoding_columns = ['item_id', 'dept_id', 'store_id', 'weekday', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "        for col in label_encoding_columns:\n",
    "            label_encoder = LabelEncoder()\n",
    "            X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "            X_test[col] = X_test[col].map(lambda s: label_encoder.transform([s])[0] if str(s) in label_encoder.classes_ else -1)\n",
    "\n",
    "            self.encoders[col] = label_encoder\n",
    "        return X_train, X_test\n",
    "    \n",
    "    def get_scaled_data(self, X_train, X_test):\n",
    "        numeric_cols = ['sell_price', 'lag_28', 'lag_7', 'rolling_mean_28']\n",
    "        scaler = StandardScaler()\n",
    "        X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "        X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "        self.scaler = scaler\n",
    "        return X_train, X_test\n",
    "    \n",
    "    def begin_preprocessing(self):\n",
    "        X_tr, X_te, y_tr, y_te = self.get_train_test_split()\n",
    "        X_tr, X_te = self.get_nan_value_imputing(X_tr, X_te)\n",
    "        X_tr, X_te = self.get_label_encoding(X_tr, X_te)\n",
    "        X_tr, X_te = self.get_scaled_data(X_tr, X_te)\n",
    "        return X_tr, X_te, y_tr, y_te \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1a98e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PreProcessor(final_df)\n",
    "X_train, X_test, y_train, y_test = preprocessor.begin_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e468a502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'dept_id', 'store_id', 'state_id', 'weekday', 'month',\n",
       "       'week_of_month', 'event_name_1', 'event_type_1', 'event_name_2',\n",
       "       'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_28',\n",
       "       'lag_7', 'rolling_mean_28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aa1a567c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'dept_id', 'store_id', 'state_id', 'weekday', 'month',\n",
       "       'week_of_month', 'event_name_1', 'event_type_1', 'event_name_2',\n",
       "       'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_28',\n",
       "       'lag_7', 'rolling_mean_28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "505e35fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id            0\n",
      "dept_id            0\n",
      "store_id           0\n",
      "state_id           0\n",
      "weekday            0\n",
      "month              0\n",
      "week_of_month      0\n",
      "event_name_1       0\n",
      "event_type_1       0\n",
      "event_name_2       0\n",
      "event_type_2       0\n",
      "snap_CA            0\n",
      "snap_TX            0\n",
      "snap_WI            0\n",
      "sell_price         0\n",
      "lag_28             0\n",
      "lag_7              0\n",
      "rolling_mean_28    0\n",
      "dtype: int64\n",
      "item_id            0\n",
      "dept_id            0\n",
      "store_id           0\n",
      "state_id           0\n",
      "weekday            0\n",
      "month              0\n",
      "week_of_month      0\n",
      "event_name_1       0\n",
      "event_type_1       0\n",
      "event_name_2       0\n",
      "event_type_2       0\n",
      "snap_CA            0\n",
      "snap_TX            0\n",
      "snap_WI            0\n",
      "sell_price         0\n",
      "lag_28             0\n",
      "lag_7              0\n",
      "rolling_mean_28    0\n",
      "dtype: int64\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.isna().sum())\n",
    "print(X_test.isna().sum())\n",
    "print(y_train.isna().sum())\n",
    "print(y_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5123bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, models):\n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        train_model_score = r2_score(y_train, y_train_pred)\n",
    "        test_model_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "        report = {}\n",
    "\n",
    "        report[list(models.keys())[i]] = test_model_score\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b7022e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0cf24451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModelTrainer:\n",
    "#     def __init__(self, X_train, y_train, X_test, y_test):\n",
    "#         self.X_train = X_train\n",
    "#         self.y_train = y_train\n",
    "#         self.X_test = X_test\n",
    "#         self.y_test = y_test\n",
    "#         self.model = None\n",
    "#         self.model_name = None\n",
    "\n",
    "#     def get_array(self):\n",
    "#         return (\n",
    "#             np.array(self.X_train),\n",
    "#             np.array(self.X_test),\n",
    "#             np.array(self.y_train),\n",
    "#             np.array(self.y_test)\n",
    "#         )\n",
    "\n",
    "#     def get_best_model(self):\n",
    "#         X_train, X_test, y_train, y_test = self.get_array()\n",
    "#         models = {\n",
    "#             'random forest': RandomForestRegressor(),\n",
    "#             'adaboost': AdaBoostRegressor(),\n",
    "#             'gradient boost': GradientBoostingRegressor(),\n",
    "#             'cat boost': CatBoostRegressor(verbose=False),\n",
    "#             'xgboost': XGBRegressor()\n",
    "#         }\n",
    "#         model_report = evaluate_model(X_train, y_train, X_test, y_test, models)\n",
    "#         best_model_score = max(model_report.values())\n",
    "#         best_model_name = list(model_report.keys())[list(model_report.values()).index(best_model_score)]\n",
    "#         best_model = models[best_model_name]\n",
    "\n",
    "#         if best_model_score < 0.8:\n",
    "#             print(\"No suitable model found.\")\n",
    "#         else:\n",
    "#             print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "#         best_model.fit(X_train, y_train)\n",
    "#         self.model = best_model\n",
    "#         self.model_name = best_model_name\n",
    "\n",
    "#     def get_model_accuracy(self):\n",
    "#         X_train, X_test, y_train, y_test = self.get_array()\n",
    "#         y_train_pred = self.model.predict(X_train)\n",
    "#         y_test_pred = self.model.predict(X_test)\n",
    "\n",
    "#         return {\n",
    "#             'training_accuracy': r2_score(y_train, y_train_pred),\n",
    "#             'test_accuracy': r2_score(y_test, y_test_pred)\n",
    "#         }\n",
    "\n",
    "#     def begin_model_training(self):\n",
    "#         self.get_best_model()\n",
    "#         model_accuracy = self.get_model_accuracy()\n",
    "#         return model_accuracy, self.model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3613a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_trainer = ModelTrainer(X_train, y_train, X_test, y_test)\n",
    "# model_trainer.begin_model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "15c5fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a00d7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 23:23:13,326] A new study created in memory with name: lgbm_gpu_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-07-02 23:23:25,910] Trial 1 failed with parameters: {'learning_rate': 0.015526965272905651, 'num_leaves': 210, 'max_depth': 5, 'min_child_samples': 14, 'subsample': 0.6652129079081117, 'colsample_bytree': 0.5662058555776878, 'reg_alpha': 5.085062437832528e-07, 'reg_lambda': 2.6943412797410833} because of the following error: LightGBMError('Check failed: (best_split_info.left_count) > (0) at D:\\\\a\\\\1\\\\s\\\\lightgbm-python\\\\src\\\\treelearner\\\\serial_tree_learner.cpp, line 852 .\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahic\\AppData\\Local\\Temp\\ipykernel_11160\\536518749.py\", line 31, in objective\n",
      "    model.fit(\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1398, in fit\n",
      "    super().fit(\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1049, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\engine.py\", line 322, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 4154, in update\n",
      "    _safe_call(\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: Check failed: (best_split_info.left_count) > (0) at D:\\a\\1\\s\\lightgbm-python\\src\\treelearner\\serial_tree_learner.cpp, line 852 .\n",
      "\n",
      "[W 2025-07-02 23:23:25,923] Trial 1 failed with value None.\n",
      "[W 2025-07-02 23:23:25,952] Trial 0 failed with parameters: {'learning_rate': 0.16138685586139057, 'num_leaves': 140, 'max_depth': 15, 'min_child_samples': 21, 'subsample': 0.7376984518168329, 'colsample_bytree': 0.6397869167658993, 'reg_alpha': 0.00015269308651525532, 'reg_lambda': 4.230685095923192e-05} because of the following error: LightGBMError('Check failed: (best_split_info.right_count) > (0) at D:\\\\a\\\\1\\\\s\\\\lightgbm-python\\\\src\\\\treelearner\\\\serial_tree_learner.cpp, line 862 .\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahic\\AppData\\Local\\Temp\\ipykernel_11160\\536518749.py\", line 31, in objective\n",
      "    model.fit(\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1398, in fit\n",
      "    super().fit(\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1049, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\engine.py\", line 322, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 4154, in update\n",
      "    _safe_call(\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: Check failed: (best_split_info.right_count) > (0) at D:\\a\\1\\s\\lightgbm-python\\src\\treelearner\\serial_tree_learner.cpp, line 862 .\n",
      "\n",
      "[W 2025-07-02 23:23:25,958] Trial 0 failed with value None.\n",
      "[W 2025-07-02 23:23:26,048] Trial 3 failed with parameters: {'learning_rate': 0.09802507073897129, 'num_leaves': 91, 'max_depth': 8, 'min_child_samples': 18, 'subsample': 0.6864413870395075, 'colsample_bytree': 0.7724550470126904, 'reg_alpha': 6.373878214513214, 'reg_lambda': 2.652006723329812e-06} because of the following error: LightGBMError('Check failed: (best_split_info.left_count) > (0) at D:\\\\a\\\\1\\\\s\\\\lightgbm-python\\\\src\\\\treelearner\\\\serial_tree_learner.cpp, line 852 .\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahic\\AppData\\Local\\Temp\\ipykernel_11160\\536518749.py\", line 31, in objective\n",
      "    model.fit(\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1398, in fit\n",
      "    super().fit(\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1049, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\engine.py\", line 322, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 4154, in update\n",
      "    _safe_call(\n",
      "  File \"e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 313, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode(\"utf-8\"))\n",
      "lightgbm.basic.LightGBMError: Check failed: (best_split_info.left_count) > (0) at D:\\a\\1\\s\\lightgbm-python\\src\\treelearner\\serial_tree_learner.cpp, line 852 .\n",
      "\n",
      "[W 2025-07-02 23:23:26,049] Trial 3 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppose X_train, X_test, y_train, y_test are already prepared\n",
    "# Use your PreProcessor class as you did earlier.\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'device': 'gpu',                 # ✅ USE GPU\n",
    "        'gpu_use_dp': False,             # faster on most GPUs\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 16),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'n_estimators': 10000\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(50),\n",
    "        lgb.log_evaluation(0)  # disables printing\n",
    "    ]\n",
    ")\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    preds = np.maximum(preds, 0)\n",
    "\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "# Optuna study with parallel jobs\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name='lgbm_gpu_study'\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=50, n_jobs=4)  # ✅ parallel trials\n",
    "\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "print(\"Best parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "940b2882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 980\n",
      "[LightGBM] [Info] Number of data points in the train set: 1707440, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 38.491934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\environments\\wallmart_hackathon\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae51a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f3637311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.7705896601009132\n"
     ]
    }
   ],
   "source": [
    "## root mean square log error\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import numpy as np\n",
    "y_pred_clipped = np.maximum(y_pred, 0)\n",
    "y_test_clipped = np.maximum(y_test, 0)\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_test_clipped, y_pred_clipped))\n",
    "print(\"RMSLE:\", rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "136e0983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE: 50.48993594457012\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(\n",
    "        2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8)\n",
    "    )\n",
    "\n",
    "print(\"SMAPE:\", smape(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "640ae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e2f57e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228666589939952"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test_clipped, y_pred_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88915a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dfaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
